{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-01T09:29:41.111438Z",
     "start_time": "2025-08-01T09:29:40.520656Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# FEATURE SCALING EXPLANATION:\n",
    "#   - Using RobustScaler for Amount is recommended because:\n",
    "#     1. Transaction amounts often contain extreme outliers (e.g., very large purchases)\n",
    "#     2. RobustScaler uses median and IQR (Interquartile Range), making it resistant to outliers\n",
    "\n",
    "df['scaled_amount'] = RobustScaler().fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['scaled_time'] = StandardScaler().fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "df.drop(['Time','Amount'], axis=1, inplace=True)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T09:29:43.999689Z",
     "start_time": "2025-08-01T09:29:43.908190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "X_base, X_test, y_base, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ],
   "id": "33dcf00616ab85e4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T09:29:46.784267Z",
     "start_time": "2025-08-01T09:29:46.610791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, average_precision_score, precision_recall_curve\n",
    "import time\n",
    "\n",
    "\n",
    "def evaluate_sampling_strategy(sampling_method, X_train, y_train, X_val, y_val):\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='aucpr',\n",
    "        learning_rate=0.01,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        gamma=0.5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    if sampling_method == 'SMOTE':\n",
    "        smote = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=5)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    elif sampling_method == 'Under-Sampling':\n",
    "        # Notice that the sampling is only on training data, that is why creating df_train rather than\n",
    "        # using df directly\n",
    "        df_train = pd.concat([X_train, y_train], axis=1)\n",
    "        df_normal = df_train[df_train['Class'] == 0]\n",
    "        df_fraud = df_train[df_train['Class'] == 1]\n",
    "        df_normal_sampled = df_normal.sample(n=len(df_fraud), random_state=42)\n",
    "        df_balanced = pd.concat([df_normal_sampled, df_fraud])\n",
    "\n",
    "        X_resampled = df_balanced.drop('Class', axis=1)\n",
    "        y_resampled = df_balanced['Class']\n",
    "    else:\n",
    "        X_resampled, y_resampled = X_train, y_train\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "    recall = TP / (TP + FN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    pr_auc = average_precision_score(y_val, y_pred_proba)\n",
    "\n",
    "    return {\n",
    "        'method': sampling_method,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1,\n",
    "        'pr_auc': pr_auc,\n",
    "        'training_time': training_time,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n"
   ],
   "id": "a8652ac7e882786e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T09:29:57.269464Z",
     "start_time": "2025-08-01T09:29:51.457040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = {'SMOTE':[], 'Under-Sampling':[], 'No-Sampling':[]}\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_base, y_base)):\n",
    "    print(f'\\n{'='*30} Fold {fold_idx} {'='*30}')\n",
    "    X_train, X_val = X_base.iloc[train_idx], X_base.iloc[val_idx]\n",
    "    y_train, y_val = y_base.iloc[train_idx], y_base.iloc[val_idx]\n",
    "\n",
    "    for method in ['SMOTE', 'Under-Sampling', 'No-Sampling']:\n",
    "        fold_result = evaluate_sampling_strategy(method, X_train, y_train, X_val, y_val)\n",
    "        results[method].append(fold_result)\n",
    "        print(f'{method} :Recall = {fold_result['recall']:.4f}, Precision = {fold_result['precision']:.4f}, F1 = {fold_result['f1']:.4f}')"
   ],
   "id": "9aee00c3b55e953b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Fold 0 ==============================\n",
      "SMOTE :Recall = 0.8974, Precision = 0.1354, F1 = 0.2353\n",
      "Under-Sampling :Recall = 0.9359, Precision = 0.0385, F1 = 0.0739\n",
      "No-Sampling :Recall = 0.6667, Precision = 0.9630, F1 = 0.7879\n",
      "\n",
      "============================== Fold 1 ==============================\n",
      "SMOTE :Recall = 0.8101, Precision = 0.1432, F1 = 0.2433\n",
      "Under-Sampling :Recall = 0.8861, Precision = 0.0459, F1 = 0.0873\n",
      "No-Sampling :Recall = 0.5190, Precision = 1.0000, F1 = 0.6833\n",
      "\n",
      "============================== Fold 2 ==============================\n",
      "SMOTE :Recall = 0.8608, Precision = 0.1001, F1 = 0.1794\n",
      "Under-Sampling :Recall = 0.8734, Precision = 0.0589, F1 = 0.1103\n",
      "No-Sampling :Recall = 0.6835, Precision = 0.9643, F1 = 0.8000\n",
      "\n",
      "============================== Fold 3 ==============================\n",
      "SMOTE :Recall = 0.9241, Precision = 0.1308, F1 = 0.2292\n",
      "Under-Sampling :Recall = 0.9367, Precision = 0.0460, F1 = 0.0876\n",
      "No-Sampling :Recall = 0.6582, Precision = 0.9123, F1 = 0.7647\n",
      "\n",
      "============================== Fold 4 ==============================\n",
      "SMOTE :Recall = 0.8987, Precision = 0.1376, F1 = 0.2387\n",
      "Under-Sampling :Recall = 0.8987, Precision = 0.0415, F1 = 0.0793\n",
      "No-Sampling :Recall = 0.5823, Precision = 0.9583, F1 = 0.7244\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T09:36:30.541346Z",
     "start_time": "2025-08-01T09:36:29.196469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "summary_dfs = {}\n",
    "for method, fold_results in results.items():\n",
    "    df_method = pd.DataFrame(fold_results)\n",
    "    df_method['fold'] = range(1, len(fold_results)+1)\n",
    "    summary_dfs[method] = df_method\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n{method} Performance:\")\n",
    "    print(f\"Average Recall: {df_method['recall'].mean():.4f}\")\n",
    "    print(f\"Average Precision: {df_method['precision'].mean():.4f}\")\n",
    "    print(f\"Average F1-Score: {df_method['f1'].mean():.4f}\")\n",
    "    print(f\"Average PR-AUC: {df_method['pr_auc'].mean():.4f}\")\n",
    "    print(f\"Average Training Time: {df_method['training_time'].mean():.2f} sec\")\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL MODEL TRAINING WITH BEST SAMPLING METHOD\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training Final XGBoost Model with Best Sampling Strategy\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_method = max(results, key=lambda k: np.mean([r['f1'] for r in results[k]]))\n",
    "print(f\"Selected best sampling method: {best_method}\")\n",
    "\n",
    "if best_method == 'SMOTE':\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=5)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_base, y_base)\n",
    "elif best_method == 'Under-sampling':\n",
    "    df_base = pd.concat([X_base, y_base], axis=1)\n",
    "    df_normal = df_base[df_base['Class'] == 0]\n",
    "    df_fraud = df_base[df_base['Class'] == 1]\n",
    "    df_normal_sampled = df_normal.sample(n=len(df_fraud), random_state=42)\n",
    "    balanced_df = pd.concat([df_normal_sampled, df_fraud])\n",
    "    X_resampled = balanced_df.drop('Class', axis=1)\n",
    "    y_resampled = balanced_df['Class']\n",
    "else:\n",
    "    X_resampled, y_resampled = X_base, y_base\n",
    "\n",
    "# Train final model on full base data\n",
    "final_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='aucpr',\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=0.5,\n",
    "    n_estimators=500,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "final_model.fit(X_resampled, y_resampled)\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Final model trained in {training_time:.2f} seconds\")"
   ],
   "id": "d69cecf112f5d249",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SMOTE Performance:\n",
      "Average Recall: 0.8782\n",
      "Average Precision: 0.1294\n",
      "Average F1-Score: 0.2252\n",
      "Average PR-AUC: 0.7346\n",
      "Average Training Time: 0.49 sec\n",
      "\n",
      "Under-Sampling Performance:\n",
      "Average Recall: 0.9062\n",
      "Average Precision: 0.0461\n",
      "Average F1-Score: 0.0877\n",
      "Average PR-AUC: 0.7243\n",
      "Average Training Time: 0.18 sec\n",
      "\n",
      "No-Sampling Performance:\n",
      "Average Recall: 0.6219\n",
      "Average Precision: 0.9596\n",
      "Average F1-Score: 0.7521\n",
      "Average PR-AUC: 0.8207\n",
      "Average Training Time: 0.31 sec\n",
      "\n",
      "==================================================\n",
      "Training Final XGBoost Model with Best Sampling Strategy\n",
      "==================================================\n",
      "Selected best sampling method: No-Sampling\n",
      "Final model trained in 1.34 seconds\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
